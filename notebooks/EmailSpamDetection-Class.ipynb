{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email Spam Detection\n",
    "#### Source can also be from https://www.kaggle.com/code/mfaisalqureshi/email-spam-detection-98-accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install termcolor # This will help you print text with colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, file operations\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from termcolor import colored\n",
    "import json\n",
    "import yaml\n",
    "import sys # appending path to current project\n",
    "import os # importing to get path\n",
    "\n",
    "# Build the model\n",
    "#CounterVectorizer Convert the text into matrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Naive Bayes Have three Classifier(Bernouli,Multinominal,Gaussian) \n",
    "# Here we use Multinominal Bayes Because the data is in a discrete form \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline # KR: What does this pipeline do?\n",
    "# Training the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append(os.path.abspath('../Libraries'))\n",
    "from model_info import ModelInfo # from filename without .py import class_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a class to hold information of the selected model\n",
    "# class ModelInfo:\n",
    "    \n",
    "#     def __init__(self) -> None:\n",
    "#         self.ModelName = \"No Model Selected\"\n",
    "#         self.Model = None\n",
    "#         self.Tokenizer = None\n",
    "#         self.AccuracyScore = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamDetector:\n",
    "        \n",
    "    def __load_json_configurations(self):\n",
    "        with open(\"../configuration/config.json\") as f:\n",
    "            config = json.load(f)\n",
    "\n",
    "        self.__configs[\"enable_trace\"] = config[\"Settings\"][\"enable_trace\"]\n",
    "        self.__configs[\"log_level\"] = config[\"Settings\"][\"log_level\"]\n",
    "        self.__configs[\"log_path\"] = config[\"Settings\"][\"log_path\"]\n",
    "        # self.__configs[\"host\"] = config[\"Database\"][\"host\"]\n",
    "    \n",
    "    def __load_yaml_configurations(self):\n",
    "        with open(\"../configuration/config.yaml\") as f:\n",
    "            config = yaml.safe_load(f)\n",
    "\n",
    "        self.__configs[\"enable_trace\"] = config[\"Settings\"][\"enable_trace\"]\n",
    "        self.__configs[\"log_level\"] = config[\"Settings\"][\"log_level\"]\n",
    "        self.__configs[\"log_path\"] = config[\"Settings\"][\"log_path\"]\n",
    "        # self.__configs[\"host\"] = config[\"Database\"][\"host\"]\n",
    "        \n",
    "    def __load_data(self):\n",
    "        df = pd.read_csv('../data/raw/mail_data.csv')\n",
    "        return df\n",
    "\n",
    "    def __extract_transform_load(self, df):\n",
    "        # Checking for null\n",
    "        empty_record_total = df.isna().sum()\n",
    "        print (f\"empty_record_total:{empty_record_total}\")\n",
    "        \n",
    "        # Add a category which is numerical\n",
    "        df[\"IsSpam\"] = df['Category'].map({'spam': 1, 'ham': 0}) # an alternate way to set the values instead of using lambda\n",
    "        # df[\"IsSpam1\"] = df['Category'].apply(lambda x:1 if x=='spam' else 0) # We need numerical column for our AI Model\n",
    "    \n",
    "    # Defining all the models that i want to try into a dictionary\n",
    "    # TODO: KR: Read these information from a config file and write a function to load this as a pipe\n",
    "    # TODO: KR: Make the algorithms dynamic so that we can build a class to add new models without touching the code\n",
    "    def __get_training_models(self):\n",
    "        self.__models_dict = {\n",
    "            \"Logistic Regression\": LogisticRegression(),\n",
    "            \"Naive Bayes Multinomia\": MultinomialNB()\n",
    "        }\n",
    "        return self.__models_dict\n",
    "        \n",
    "    def __select_best_model(self, df):\n",
    "        # Loop through the models and for each model you will have to train and test and get the accuracy\n",
    "        # Since we canot loop and reference via index, we are converting the dictionary to a list\n",
    "        models_dict = self.__get_training_models()\n",
    "        models_list = list(models_dict)\n",
    "        models_values_list = list(models_dict.values())\n",
    "        temp_average_score = 0.0\n",
    "        models_info = list()\n",
    "        selected_model = ModelInfo()\n",
    "        recomended_model_count = len(models_list)\n",
    "        trace_enabled = self.__configs['enable_trace']\n",
    "        \n",
    "        print(colored(f\"self.__configs.enable_trace: {self.__configs['enable_trace']}\", \"red\"))\n",
    "        \n",
    "        if (trace_enabled):\n",
    "            print(f\"Recomended Models Count: {recomended_model_count}\")\n",
    "            \n",
    "        for l in range(len(models_list)):\n",
    "            print(colored(f\"\\nCurrent Model: {models_list[l]} [{models_values_list[l]}]\", 'yellow'))\n",
    "            model = models_values_list[l]\n",
    "            # vectorize the x_train data and x_test data\n",
    "            vectorizer = TfidfVectorizer(min_df=1, stop_words='english', lowercase=True) # object to tokenize the messages\n",
    "\n",
    "            # Calculating the mean of the accuracy so that way we know if this would work for various test data\n",
    "            meanAccuracy_train_data = 0.0\n",
    "            repeatCount = 20 # Ensure we get the accuracy for different train data\n",
    "            for i in range(0, repeatCount, 1):\n",
    "                x_train, x_test, y_train, y_test = train_test_split(df['Message'], df['IsSpam'], test_size=0.20)\n",
    "                \n",
    "                x_train_vect = vectorizer.fit_transform(x_train)\n",
    "                x_test_vect = vectorizer.transform(x_test)\n",
    "\n",
    "                # fit the vector data into the model\n",
    "                model.fit(x_train_vect, y_train)\n",
    "                \n",
    "                y_pred = model.predict(x_test_vect) # test with vectorized test data\n",
    "\n",
    "                # calculate the accuracy score for the model\n",
    "                accuracyScore = accuracy_score(y_test, y_pred)\n",
    "                if (trace_enabled):\n",
    "                    print (f'\\t The accuracy score for the model {model} iteration {i} is {accuracyScore}')\n",
    "                meanAccuracy_train_data += accuracyScore\n",
    "\n",
    "                # Predicting\n",
    "                # y_train_pred = pipe.predict\n",
    "\n",
    "            meanAccuracy_train_data = meanAccuracy_train_data / repeatCount\n",
    "            print(colored(f'Mean Accuracy Score [{repeatCount} Iterations]: {meanAccuracy_train_data}', 'magenta'))\n",
    "            \n",
    "            if (trace_enabled):\n",
    "                print(f\"\\tcurrent_model.AccuracyScore: {meanAccuracy_train_data}, \\n\\tcurrent_model.ModelName: {models_list[l]}, \\n\\tcurrent_model.Model: {model}, \\n\\tcurrent_model.Tokenizer: {vectorizer}\")\n",
    "\n",
    "            current_model = ModelInfo()\n",
    "            current_model.AccuracyScore = meanAccuracy_train_data\n",
    "            current_model.ModelName = models_list[l]\n",
    "            current_model.Model = model\n",
    "            current_model.Tokenizer = vectorizer\n",
    "            models_info.append(current_model)\n",
    "            \n",
    "            if (trace_enabled):\n",
    "                print(f\"\\tmodels_info_count: {len(models_info)}, models_info_type: {type(models_info)}\")\n",
    "                print(f\"\\t index:{l}, {models_info[l].Model}\")\n",
    "                #print(f\"\\t index:{l+1}, {models_info[l+1].Model}\")\n",
    "            sel_model_accuracy = np.nan_to_num(selected_model.AccuracyScore)\n",
    "            \n",
    "            #print(f\"Selected Model's Accuracy:{sel_model_accuracy}, Current Model's Accuracy:{current_model.AccuracyScore}\")\n",
    "            if (sel_model_accuracy < current_model.AccuracyScore):\n",
    "                selected_model = current_model\n",
    "\n",
    "        # if the accuracy score is mre than the other ones, than we need to take the best algorithm to predict.\n",
    "        for m in models_info:\n",
    "            print(f'Model Name:{m.ModelName} with accuracy {m.AccuracyScore}')\n",
    "            \n",
    "        return selected_model\n",
    "    \n",
    "    def IsSpam(self, message):\n",
    "        input_data_features = self.selected_model.Tokenizer.transform([message])\n",
    "\n",
    "        output = self.selected_model.Model.predict(input_data_features)\n",
    "        result_code = output[0]\n",
    "        if (1 == result_code):\n",
    "            result_text = \"Spam\"\n",
    "        else:\n",
    "            result_text = \"Not a Spam\"\n",
    "        print(f\"The prediction by the algorithm {x.selected_model.Model} is {result_text} [{result_code}]\")\n",
    "        \n",
    "        return result_code, result_text\n",
    "        # response_data = {\n",
    "        #     \"code\": result_code,\n",
    "        #     \"description\": result_text\n",
    "        # }\n",
    "        \n",
    "        # return json.dump(response_data)\n",
    "        \n",
    "        \n",
    "    def __init__ (self) -> None:\n",
    "        self.__configs = {\n",
    "                \"enable_trace\": False,\n",
    "                \"log_level\": \"DEBUG\",\n",
    "                \"log_path\": \".\"\n",
    "            }\n",
    "        # load configuration files\n",
    "        self.__load_json_configurations()\n",
    "        \n",
    "        self.__df = self.__load_data()\n",
    "        self.__extract_transform_load(self.__df)\n",
    "        \n",
    "        # Selecting the best model based on the data that was given\n",
    "        self.selected_model = self.__select_best_model(self.__df)\n",
    "        print(f\"\\n The selected Model's Name: {self.selected_model.ModelName}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty_record_total:Category    0\n",
      "Message     0\n",
      "dtype: int64\n",
      "\u001b[31mself.__configs.enable_trace: False\u001b[0m\n",
      "\u001b[33m\n",
      "Current Model: Logistic Regression [LogisticRegression()]\u001b[0m\n",
      "\u001b[35mMean Accuracy Score [20 Iterations]: 0.9638116591928252\u001b[0m\n",
      "\u001b[33m\n",
      "Current Model: Naive Bayes Multinomia [MultinomialNB()]\u001b[0m\n",
      "\u001b[35mMean Accuracy Score [20 Iterations]: 0.9696860986547087\u001b[0m\n",
      "Model Name:Logistic Regression with accuracy 0.9638116591928252\n",
      "Model Name:Naive Bayes Multinomia with accuracy 0.9696860986547087\n",
      "\n",
      " The selected Model's Name: Naive Bayes Multinomia\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Naive Bayes Multinomia'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = SpamDetector()\n",
    "x.selected_model.ModelName\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction by the algorithm MultinomialNB() is Spam [1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 'Spam')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = x.IsSpam(\"Free entry in 2 a wkly comp to win FA Cup\")\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
